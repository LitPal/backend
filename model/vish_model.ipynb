{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "662f8c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (0.0.330)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from langchain) (3.5.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.0.57)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from anyio<4.0->langchain) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pinecone-client in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (2.2.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from pinecone-client) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.4 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from pinecone-client) (6.0.1)\n",
      "Requirement already satisfied: loguru>=0.5.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from pinecone-client) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from pinecone-client) (4.7.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from pinecone-client) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from pinecone-client) (1.26.16)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from pinecone-client) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from pinecone-client) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pinecone-client) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vishnuvelayuthan/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pinecone-client) (2023.7.22)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install langchain\n",
    "!pip3 install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b41fd2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1adafb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishnuvelayuthan/computer-science/Hackathons/HackSCX-2023/backend/backend-env/lib/python3.11/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "import pinecone\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0932e2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_docs(directory):\n",
    "  loader = DirectoryLoader(directory)\n",
    "  documents = loader.load()\n",
    "  return documents\n",
    "\n",
    "documents = load_docs(\"data\")\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "504c88aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def split_docs(documents, chunk_size=1000, chunk_overlap=20):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "  return docs\n",
    "\n",
    "docs = split_docs(documents)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "299c80c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishnuvelayuthan/computer-science/Hackathons/HackSCX-2023/backend/backend-env/lib/python3.11/site-packages/langchain/embeddings/openai.py:217: UserWarning: WARNING! model_name is not default parameter.\n",
      "                    model_name was transferred to model_kwargs.\n",
      "                    Please confirm that model_name is what you intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embeddings = OpenAIEmbeddings(model_name=\"ada\")\n",
    "\n",
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "len(query_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a1abf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key=\"b3c95e66-d3bc-41fc-ae63-21dcd3f36212\",\n",
    "    environment=\"us-west4-gcp-free\"\n",
    ")\n",
    "\n",
    "index_name = \"hacksc\"\n",
    "\n",
    "index = Pinecone.from_documents(docs, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b446279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_docs(query, k=3, score=False):  # we can control k value to get no. of context with respect to question.\n",
    "  if score:\n",
    "    similar_docs = index.similarity_search_with_score(query, k=k)\n",
    "  else:\n",
    "    similar_docs = index.similarity_search(query, k=k)\n",
    "  return similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af9b348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Attention mechanisms have become an integral part of compelling sequence modeling and transduc- tion models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences [2|{16]. In all but a few cases [22]], however, such attention mechanisms are used in conjunction with a recurrent network.\\n\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output. The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P1O0 GPUs.\\n\\n2 Background', metadata={'source': 'data/file.txt'}),\n",
       " Document(page_content='Attention mechanisms have become an integral part of compelling sequence modeling and transduc- tion models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences [2|{16]. In all but a few cases [22]], however, such attention mechanisms are used in conjunction with a recurrent network.\\n\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output. The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P1O0 GPUs.\\n\\n2 Background', metadata={'source': 'data/file.txt'}),\n",
       " Document(page_content='Attention mechanisms have become an integral part of compelling sequence modeling and transduc- tion models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences [2|{16]. In all but a few cases [22]], however, such attention mechanisms are used in conjunction with a recurrent network.\\n\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output. The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P1O0 GPUs.\\n\\n2 Background', metadata={'source': 'data/file.txt'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_docs(\"What is a transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "615c78fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llm import AzureOpenAI\n",
    "model_name = \"text-davinci-003\"\n",
    "# llm = AzureOpenAI(model_name=model_name)\n",
    "\n",
    "# chain = load_qa_chain(llm, chain_type=\"stuff\") #we can use map_reduce chain_type also.\n",
    "\n",
    "def get_answer(query):\n",
    "    similar_docs = get_similar_docs(query)\n",
    "    prompt = f\"\"\"\n",
    "            You are reading a mentor chatbot. The chatbot is designed to help you with questions about the research paper.\n",
    "            Response should be very similar to the original paper. But also simplified to help the mentee understand the paper.\n",
    "            Below is a query I received from the mentee:\n",
    "            {query}\n",
    "\n",
    "            Below is {len(similar_docs)} paragraphs from the document that give context to the solution:\n",
    "        \"\"\"\n",
    "    for docs in similar_docs:\n",
    "        prompt += docs.page_content + \"\\n\"\n",
    "    \n",
    "    prompt += \"\\n\"\n",
    "    \n",
    "    prompt += \"\"\"\n",
    "        Please write the best response that I should send to this prospect, and also don't make it too long:\n",
    "\n",
    "        \"\"\"\n",
    "    answer = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\n",
    "        \"role\" : \"user\", \"content\" : prompt\n",
    "    }])\n",
    "#   answer = chain.run(input_documents=similar_docs, question=query)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42a6ff2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8HbgUYB8I4dawvUGYbKqKadhZZAwA at 0x174fb9250> JSON: {\n",
       "  \"id\": \"chatcmpl-8HbgUYB8I4dawvUGYbKqKadhZZAwA\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1699207126,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"A transformer is a model architecture that is used for sequence modeling and translation tasks. It relies on an attention mechanism to model dependencies between input and output sequences without the need for recurrence. This allows for more parallelization and has been shown to achieve state-of-the-art translation quality after being trained for just twelve hours on a specific type of GPUs. In contrast, most attention mechanisms are used along with a recurrent network. Overall, the transformer offers a more efficient way to handle dependencies in sequence modeling and translation tasks.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 525,\n",
       "    \"completion_tokens\": 101,\n",
       "    \"total_tokens\": 626\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(\"What is a transformer?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc8b709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack-sc",
   "language": "python",
   "name": "hack-sc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
